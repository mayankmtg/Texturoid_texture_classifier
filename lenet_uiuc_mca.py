# -*- coding: utf-8 -*-
"""Lenet_uiuc_MCA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a3_csWC0aOAlUj0Fp53sNFWDUrT7qVfJ

### Imports
"""

import torch.nn as nn
import torch
import numpy as np
import pickle
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from imutils import paths
from PIL import Image
import random
import json

from google.colab import drive
drive.mount('/content/drive')

"""### Set Parameters here"""

test_size = 0.15
learning_rate = 0.01
epochs = 25
batch_size = 16



def extract_features(path):
    img = Image.open(path)
    return (np.array(img))

"""### Load Dataset"""

def gen_dataset():
  data=[]
  labels = []
  samples = 0
  imagePaths = sorted(list(paths.list_images('/content/drive/My Drive/dataset_uiuc/')))
  random.seed(42)
  random.shuffle(imagePaths)
  print (imagePaths)
  for imagePath in imagePaths:
    print (imagePath)
    data.append([extract_features(imagePath)])
    labels.append(int(imagePath.split('/')[-2].split('T')[-1]))
  return (data,labels)

images,labels = gen_dataset()
print (len(images))

data_dict = {}
data_dict["images"] = images
data_dict["labels"] = labels
with open( "/content/drive/My Drive/dataset_uiuc.pkl", "wb") as handle:
    pickle.dump(data_dict, handle)

with open("/content/drive/My Drive/dataset_uiuc.pkl", "rb") as handle:
    data_dict = pickle.load(handle)

images, labels = data_dict["images"], data_dict["labels"]
images = np.array(images)
labels = np.array(labels)
print("Images Info : ",images.shape)
print("Labels Info : ", labels.shape)

"""### Read Labels Map"""



"""### Split data for training and testing"""

train_x, test_x, train_y, test_y = train_test_split(images, labels, test_size=test_size, shuffle=True)
print("Training Images : ", train_x.shape)
print("Testing Images : ", test_x.shape)
print("Training Labels : ", train_y.shape)
print("Testing Labels : ", test_y.shape)

"""### Convolutional Neural Network"""

class ConvNet(nn.Module):
    
    def __init__(self, input_img_size, num_classes):
        super(ConvNet, self).__init__()
        
        self.image_in_size = input_img_size
        self.num_classes = num_classes
        
        # in_channels, out_channels, kernel_size, stride, padding - conv2d
        # kernel_size, stride - avg pool, stride = None (kerne size)
        self.conv1 = nn.Conv2d(1, 32, (3,3), 1)
        self.pool1 = nn.MaxPool2d((2, 2))
        self.conv2 = nn.Conv2d(32, 32, (2,2), 1)
        self.pool2 = nn.MaxPool2d((2, 2))
        self.conv3 = nn.Conv2d(32, 64, (2,2), 2, 1)
        self.pool3 = nn.MaxPool2d((2,2))
        
        self.activation = nn.ReLU()
        
        # in_features, out_features
        self.fc1 = nn.Linear(64*30*40, 256)
        self.fc2 = nn.Linear(256, self.num_classes)
    
    def forward(self, x, bsize):
        
        x = x.view(bsize, 1, 640, 480)
        conv_out = self.activation(self.conv1(x))
        conv_out = self.pool1(conv_out)
        conv_out = self.activation(self.conv2(conv_out))
        conv_out = self.pool2(conv_out)
        conv_out = self.activation(self.conv3(conv_out))
        conv_out = self.pool3(conv_out)
        
        fc_out = self.activation(self.fc1(conv_out.view(bsize, -1)))
        fc_out = self.fc2(fc_out)
        
        return fc_out

class ConvNet(nn.Module):
    
    def __init__(self, input_img_size, num_classes):
        super(ConvNet, self).__init__()
        
        self.image_in_size = input_img_size
        self.num_classes = num_classes
        
        # in_channels, out_channels, kernel_size, stride, padding - conv2d
        # kernel_size, stride - avg pool, stride = None (kerne size)
        self.conv1 = nn.Conv2d(1, 32, (3,3), 1)
        self.pool1 = nn.MaxPool2d((2, 2))
        self.conv2 = nn.Conv2d(32, 32, (2,2), 1)
        self.pool2 = nn.MaxPool2d((2, 2))
        self.conv3 = nn.Conv2d(32, 64, (2,2), 2, 1)
        self.pool3 = nn.MaxPool2d((2,2))
        
        self.activation = nn.ReLU()
        
        # in_features, out_features
        self.fc1 = nn.Linear(64*30*40, 256)
        self.fc2 = nn.Linear(256, self.num_classes)
    
    def forward(self, x, bsize):
        x = x.view(bsize, 1, self.image_in_size[1], self.image_in_size[2])
        conv_out = self.activation(self.conv1(x))
        conv_out = self.pool1(conv_out)
        conv_out = self.activation(self.conv2(conv_out))
        conv_out = self.pool2(conv_out)
        conv_out = self.activation(self.conv3(conv_out))
        conv_out = self.pool3(conv_out)
#         print (conv_out.shape)
#         exit(0)
        fc_out = self.activation(self.fc1(conv_out.view(bsize,-1)))
#         print(conv_out.view(,-1))
        fc_out = self.fc2(fc_out) 
        return fc_out

"""### Model and Data Prep."""

model = ConvNet(np.array(train_x[0]).shape, np.unique(train_y).shape[0])
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
criterion = nn.CrossEntropyLoss()

print (model)

"""### Training Loop"""

train_x = np.array(train_x)
for epoch in range(0, epochs):
    
    # Set model to training mode
    model = model.train()
    
    shuffled_indexes = np.arange(0, train_x.shape[0])
    np.random.shuffle(shuffled_indexes)
    
    num_iters = int(shuffled_indexes.shape[0]/batch_size)
    index = 0
    total_loss = 0.0
    
    for __iter__ in range(0, num_iters):
        train_images_batch = np.take(train_x, shuffled_indexes[index:index+batch_size], axis=0)
        train_labels_batch = np.take(train_y, shuffled_indexes[index:index+batch_size], axis=0)
        
        torch_train_x = torch.from_numpy(train_images_batch).float()
        torch_train_y = torch.from_numpy(train_labels_batch).long()
        
        #print(torch_train_x.size(), torch_train_y.size())
        model_out = model.forward(torch_train_x, bsize=torch_train_x.size()[0])
        
        loss = criterion(model_out, torch_train_y)
        
        total_loss += loss.item()
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        del torch_train_x
        del torch_train_y
    
    
    # Test Mode
    
    model = model.eval()
    
    with torch.no_grad():
        torch_test_x = torch.from_numpy(nparray(test_x)).float()
        torch_test_y = torch.from_numpy(np.array(test_y)).long()
        test_model_out = model.forward(torch_test_x, bsize=torch_test_x.size()[0])
        test_loss = criterion(test_model_out, torch_test_y)
    
    print("Epoch : %d, Train Loss : %.4f, Test Loss : %.4f"%(epoch+1, total_loss/num_iters, test_loss.item()))

export CUDA_LAUNCH_BLOCKING = 1

"""### Save trained model weights"""

torch.save(model.state_dict(), "weights.torch")

"""### Calculate Prediction Accuracy"""

model = model.eval()

with torch.no_grad():
    torch_test_x = torch.from_numpy(test_x).float().cuda()
    torch_test_y = torch.from_numpy(test_y).long().cuda()
    test_model_out = model.forward(torch_test_x, bsize=torch_test_x.size()[0])

bool_tensor = torch_test_y == test_model_out.argmax(dim=1)
correct_count = bool_tensor.sum().float().div(bool_tensor.size()[0])
print("Prediction Accuracy : %.4f"%(correct_count.item()*100))

"""### Some Sample Predictions"""

predicted_labels = test_model_out.argmax(dim=1)

fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, sharex='col', sharey='row', figsize=(14,6))
random_indexes = np.random.randint(0, torch_test_x.size()[0], size=(4,))
#print(random_indexes)
ax1.imshow(torch_test_x[random_indexes[0]].cpu().numpy(), cmap="gray")
#print(labels_encoding[str(torch_test_y[random_indexes[0]].item())])
title = "True = %s, Predicted = %s"%(labels_encoding[str(torch_test_y[random_indexes[0]].item())], labels_encoding[str(predicted_labels[random_indexes[0]].item())])
ax1.set_title(title)

ax2.imshow(torch_test_x[random_indexes[1]].cpu().numpy(), cmap="gray")
#print(labels_encoding[str(torch_test_y[random_indexes[1]].item())])
title = "True = %s, Predicted = %s"%(labels_encoding[str(torch_test_y[random_indexes[1]].item())], labels_encoding[str(predicted_labels[random_indexes[1]].item())])
ax2.set_title(title)

ax3.imshow(torch_test_x[random_indexes[2]].cpu().numpy(), cmap="gray")
#print(labels_encoding[str(torch_test_y[random_indexes[2]].item())])
title = "True = %s, Predicted = %s"%(labels_encoding[str(torch_test_y[random_indexes[2]].item())], labels_encoding[str(predicted_labels[random_indexes[2]].item())])
ax3.set_title(title)

ax4.imshow(torch_test_x[random_indexes[3]].cpu().numpy(), cmap="gray")
#print(labels_encoding[str(torch_test_y[random_indexes[3]].item())])
title = "True = %s, Predicted = %s"%(labels_encoding[str(torch_test_y[random_indexes[3]].item())], labels_encoding[str(predicted_labels[random_indexes[3]].item())])
ax4.set_title(title)
plt.show()